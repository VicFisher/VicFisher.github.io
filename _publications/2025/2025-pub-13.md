---
title:          "REaMA: Building Biomedical Relation Extraction Specialized Large Language Models Through Instruction Tuning."
date:           2025-08-20 00:01:00 +0800
selected:       false
pub:            "IEEE Transactions on Neural Networks and Learning Systems"
pub_date:       "2025"
abstract: >-
  Biomedical relation extraction (BioRE) is key for extracting semantic relations from biomedical texts, but general large language models (LLMs) like WizardLM-70B and LLaMA-2-70B perform poorly, with low F-scores (14.05 and 12.21) compared to the state-of-the-art (65.17) on the BioRED dataset. A new multitask instruction-tuning framework, using a curated dataset called REInstruct with 150,000 instruction-response pairs, transforms general LLMs into BioRE-specialized models named REaMA (7B and 13B sizes). REaMA models show strong performance across seven BioRE datasets, with REaMA-2-13B surpassing the state-of-the-art on five datasets. Adding chain-of-thought (CoT) to REInstruct further boosts REaMAâ€™s generalization. 
# cover:          /assets/images/covers/2021-1-cover.jpg
authors:
- Zhang, Y.-D.
- Yu, J.-L.
- Li, G.-B.#
- He, Z.-N.#
- Yen, Gary G. 
links:
  Code: https://github.com/stzpp/REaMA
  # Project: https://phoregen.ddtmlab.org/
  Paper: https://ieeexplore.ieee.org/abstract/document/11131263
---
